# Downloaded Papers

## Core Papers (Directly Relevant)

1. **Unnatural Language Processing: How Do Language Models Handle Machine-Generated Prompts?**
   - Authors: Kervadec, Franzon, Baroni (2023)
   - File: `2310.15829_unnatural_language_processing_machine_prompts.pdf`
   - arXiv: 2310.15829
   - Why relevant: Most directly relevant paper - compares how LMs process human vs. machine-generated prompts at mechanistic level

2. **Benchmarking Prompt Sensitivity in Large Language Models**
   - Authors: Razavi et al. (2025)
   - File: `2502.06065_benchmarking_prompt_sensitivity_llms.pdf`
   - arXiv: 2502.06065
   - Why relevant: Introduces prompt sensitivity prediction task and PromptSET dataset

3. **POSIX: A Prompt Sensitivity Index For Large Language Models**
   - Authors: Razavi et al. (2024)
   - File: `2410.02185_posix_prompt_sensitivity_index.pdf`
   - arXiv: 2410.02185
   - Why relevant: Quantitative framework for measuring prompt sensitivity

## Sycophancy Papers

4. **Towards Understanding Sycophancy in Language Models**
   - Authors: Sharma, Tong, Korbak et al. (2024) - Anthropic
   - File: `2310.13548_towards_understanding_sycophancy.pdf`
   - arXiv: 2310.13548 (ICLR 2024)
   - Why relevant: Shows LLMs adapt behavior based on perceived user preferences

5. **Simple Synthetic Data Reduces Sycophancy in Large Language Models**
   - Authors: Wei et al. (2023)
   - File: `2308.03958_simple_synthetic_data_reduces_sycophancy.pdf`
   - arXiv: 2308.03958
   - Why relevant: Demonstrates sycophancy is a trainable behavior pattern

6. **Accounting for Sycophancy in Language Model Uncertainty Estimation**
   - Authors: (2024)
   - File: `2410.14746_accounting_sycophancy_uncertainty.pdf`
   - arXiv: 2410.14746
   - Why relevant: Studies interaction between sycophancy and model confidence

7. **TRUTH DECAY: Quantifying Multi-Turn Sycophancy in Language Models**
   - Authors: (2025)
   - File: `2503.11656_truth_decay_multiturn_sycophancy.pdf`
   - arXiv: 2503.11656
   - Why relevant: Multi-turn sycophancy dynamics

8. **Not Your Typical Sycophant: The Elusive Nature of Sycophancy in LLMs**
   - Authors: (2026)
   - File: `2601.15436_not_typical_sycophant_elusive_sycophancy.pdf`
   - arXiv: 2601.15436
   - Why relevant: Novel evaluation approach for sycophancy without manipulative prompts

9. **Sycophancy in Large Language Models: Causes and Mitigations**
   - Authors: (2024)
   - File: `2411.15287_sycophancy_causes_mitigations.pdf`
   - arXiv: 2411.15287
   - Why relevant: Comprehensive survey of sycophancy causes

10. **From Yes-Men to Truth-Tellers: Addressing Sycophancy with Pinpoint Tuning**
    - Authors: (2024)
    - File: `2409.01658_yes_men_truth_tellers_sycophancy.pdf`
    - arXiv: 2409.01658
    - Why relevant: Targeted methods for reducing sycophancy

11. **The Sycophancy to Subtlety Pipeline**
    - Authors: (2024)
    - File: `2401.10580_sycophancy_to_subtlety_pipeline.pdf`
    - arXiv: 2401.10580
    - Why relevant: How sycophancy manifests in subtle vs. overt ways

## Biased/Unfaithful Reasoning Papers

12. **Language Models Don't Always Say What They Think**
    - Authors: Turpin, Michael, Perez, Bowman (2023) - NeurIPS 2023
    - File: `2305.04388_language_models_dont_say_what_they_think.pdf`
    - arXiv: 2305.04388
    - Why relevant: Shows hidden biasing features change model behavior without acknowledgment

13. **How Language Model Hallucinations Can Snowball**
    - Authors: (2023)
    - File: `2305.13534_hallucination_snowball.pdf`
    - arXiv: 2305.13534
    - Why relevant: Behavioral cascading effects in LLM responses

## Prompt Optimization & LLM-to-LLM Communication

14. **Large Language Models as Optimizers (OPRO)**
    - Authors: Yang et al. (2024) - Google DeepMind
    - File: `2309.03409_large_language_models_as_optimizers.pdf`
    - arXiv: 2309.03409
    - Why relevant: LLM-generated prompts outperform human prompts with distinctive style

15. **Encouraging Divergent Thinking in LLMs through Multi-Agent Debate**
    - Authors: Du et al. (2023)
    - File: `2305.19118_divergent_thinking_multiagent_debate.pdf`
    - arXiv: 2305.19118
    - Why relevant: LLM-to-LLM communication in debate settings

16. **ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate**
    - Authors: Chan et al. (2023)
    - File: `2308.07201_chateval_multiagent_debate_evaluators.pdf`
    - arXiv: 2308.07201
    - Why relevant: LLMs evaluating each other's outputs

## Persona & Role-Playing

17. **Persona is a Double-edged Sword: Mitigating Negative Impact of Role-playing**
    - Authors: (2024)
    - File: `2408.08631_persona_double_edged_sword_reasoning.pdf`
    - arXiv: 2408.08631
    - Why relevant: Shows persona assignment dramatically changes LLM behavior

18. **From Persona to Personalization: A Survey on Role-Playing Language Agents**
    - Authors: (2024)
    - File: `2404.18231_persona_to_personalization_survey_rpla.pdf`
    - arXiv: 2404.18231
    - Why relevant: Comprehensive survey on how personas affect LLM behavior

19. **Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization**
    - Authors: (2024)
    - File: `2406.01171_two_tales_persona_llms_survey.pdf`
    - arXiv: 2406.01171
    - Why relevant: Framework for understanding persona effects

## AI-Generated Text Detection

20. **Paraphrasing Evades Detectors of AI-Generated Text**
    - Authors: Krishna et al. (2023)
    - File: `2303.13408_paraphrasing_evades_ai_text_detectors.pdf`
    - arXiv: 2303.13408
    - Why relevant: Methods for distinguishing human vs. AI text

## LLM Evaluation & Behavior

21. **Discovering Language Model Behaviors with Model-Written Evaluations**
    - Authors: Perez et al. (2022) - Anthropic
    - File: `2212.09251_model_written_evaluations.pdf`
    - arXiv: 2212.09251
    - Why relevant: LLM-generated evaluations of LLMs; sycophancy detection methodology

22. **A Human-AI Comparative Analysis of Prompt Sensitivity in LLM-Based Relevance Judgment**
    - Authors: (2025)
    - File: `2504.12408_human_ai_comparative_prompt_sensitivity.pdf`
    - arXiv: 2504.12408
    - Why relevant: Directly compares human and AI prompt sensitivity

## Robustness

23. **PromptBench: Towards Evaluating the Robustness of LLMs on Adversarial Prompts**
    - Authors: Zhu et al. (2023)
    - File: `2306.04528_promptbench_robustness_llm.pdf`
    - arXiv: 2306.04528
    - Why relevant: Framework for testing LLM robustness to prompt variations

## LLM Societies

24. **The PIMMUR Principles: Ensuring Validity in Collective Behavior of LLM Societies**
    - Authors: Zhou et al. (2025)
    - File: `2501.10868_pimmur_principles_llm_societies.pdf`
    - arXiv: 2501.10868
    - Why relevant: Shows LLMs can detect experimental setups; methodological concerns for LLM simulations
