@article{kervadec2023unnatural,
  title={Unnatural Language Processing: Bridging the Gap Between Synthetic and Natural Language Data},
  author={Kervadec, Corentin and Franzon, Francesca and Baroni, Marco},
  journal={arXiv preprint arXiv:2310.15829},
  year={2023}
}

@inproceedings{sharma2024sycophancy,
  title={Towards Understanding Sycophancy in Language Models},
  author={Sharma, Mrinank and Tong, Meg and Korbak, Tomasz and Duvenaud, David and Askell, Amanda and Bowman, Samuel R and Cheng, Newton and Bai, Yuntao and Perez, Ethan and others},
  booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2024}
}

@inproceedings{turpin2023unfaithful,
  title={Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting},
  author={Turpin, Miles and Michael, Julian and Perez, Ethan and Bowman, Samuel R},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2023}
}

@article{razavi2025benchmarking,
  title={Benchmarking Prompt Sensitivity in Large Language Models},
  author={Razavi, Nazanin and Vechtomova, Olga and Arabzadeh, Negar},
  journal={arXiv preprint arXiv:2502.06065},
  year={2025}
}

@article{yang2024opro,
  title={Large Language Models as Optimizers},
  author={Yang, Chengrun and Wang, Xuezhi and Lu, Yifeng and Liu, Hanxiao and Le, Quoc V and Zhou, Denny and Chen, Xinyun},
  journal={arXiv preprint arXiv:2309.03409},
  year={2024}
}

@article{wei2023sycophancy,
  title={Simple Synthetic Data Reduces Sycophancy in Large Language Models},
  author={Wei, Jerry and Sharma, Mrinank and Tong, Meg and others},
  journal={arXiv preprint arXiv:2308.03958},
  year={2023}
}

@inproceedings{perez2022discovering,
  title={Discovering Language Model Behaviors with Model-Written Evaluations},
  author={Perez, Ethan and Ringer, Sam and Luko{\v{s}}i{\=u}t{\.e}, Kamil{\.e} and Nguyen, Karina and Chen, Edwin and Heiner, Scott and Pettit, Craig and Olsson, Catherine and Kundu, Sandipan and Kadavath, Saurav and others},
  booktitle={Findings of ACL},
  year={2023}
}

@article{joshi2017triviaqa,
  title={TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension},
  author={Joshi, Mandar and Choi, Eunsol and Weld, Daniel S and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1705.03551},
  year={2017}
}

@inproceedings{suzgun2023bbh,
  title={Challenging {BIG}-Bench Tasks and Whether Chain-of-Thought Can Solve Them},
  author={Suzgun, Mirac and Scales, Nathan and Sch{\"a}rli, Nathanael and Gehrmann, Sebastian and Tay, Yi and Chung, Hyung Won and Chowdhery, Aakanksha and Le, Quoc V and Chi, Ed H and Zhou, Denny and Wei, Jason},
  booktitle={Findings of ACL},
  year={2023}
}

@article{brown2020language,
  title={Language Models Are Few-Shot Learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{ouyang2022training,
  title={Training Language Models to Follow Instructions with Human Feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{mitchell2023detectgpt,
  title={DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature},
  author={Mitchell, Eric and Lee, Yoonho and Khazatsky, Alexander and Manning, Christopher D and Finn, Chelsea},
  journal={arXiv preprint arXiv:2301.11305},
  year={2023}
}

@article{sadasivan2023aigenerated,
  title={Can {AI}-Generated Text be Reliably Detected?},
  author={Sadasivan, Vinu Sankar and Kumar, Aounon and Balasubramanian, Sriram and Wang, Wenxiao and Feizi, Soheil},
  journal={arXiv preprint arXiv:2303.11156},
  year={2023}
}

@article{du2023debate,
  title={Improving Factuality and Reasoning in Language Models through Multiagent Debate},
  author={Du, Yilun and Li, Shuang and Torralba, Antonio and Tenenbaum, Joshua B and Mordatch, Igor},
  journal={arXiv preprint arXiv:2305.14325},
  year={2023}
}

@article{chan2023chateval,
  title={ChatEval: Towards Better {LLM}-based Evaluators through Multi-Agent Debate},
  author={Chan, Chi-Min and Chen, Weize and Su, Yusheng and Yu, Jianxuan and Xue, Wei and Zhang, Shanghang and Fu, Jie and Liu, Zhiyuan},
  journal={arXiv preprint arXiv:2308.07201},
  year={2023}
}

@article{razavi2024posix,
  title={{POSIX}: A Prompt Sensitivity Index for Large Language Models},
  author={Razavi, Nazanin and others},
  journal={arXiv preprint arXiv:2410.02185},
  year={2024}
}

@article{zhou2025pimmur,
  title={The {PIMMUR} Principles: Guidelines for Effective {LLM} Society Simulations},
  author={Zhou, Andy and others},
  journal={arXiv preprint arXiv:2501.10868},
  year={2025}
}

@article{anthropic2024claude,
  title={The {Claude} Model Family},
  author={{Anthropic}},
  year={2024},
  note={\url{https://www.anthropic.com}}
}

@article{openai2024gpt4,
  title={{GPT-4} Technical Report},
  author={{OpenAI}},
  journal={arXiv preprint arXiv:2303.08774},
  year={2024}
}

@article{google2024gemini,
  title={Gemini: A Family of Highly Capable Multimodal Models},
  author={{Google DeepMind}},
  journal={arXiv preprint arXiv:2312.11805},
  year={2024}
}

@book{cohen1988statistical,
  title={Statistical Power Analysis for the Behavioral Sciences},
  author={Cohen, Jacob},
  year={1988},
  edition={2nd},
  publisher={Routledge}
}
